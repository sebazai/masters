\chapter{Discussion\label{discussion}}

This chapter contains a discussion of the study, implications, limitations, and potential future research. Section 6.1 is a summary of the research questions. Section 6.2 a discussion on the study result and implications are presented. Section 6.3 presents threats to the validity of the study. Section 6.4 promotes potential future research.

\section{Summary of main findings}

Below is a recap of the research questions and a summary of the answers.

\begin{itemize}
    \item \textbf{RQ1.} What are the limitations of web accessibility evaluation tools in assessing compliance with Web Content Accessibility Guidelines (WCAG)?
\end{itemize}

    A multivocal literature review answered the current limitations of web accessibility evaluation tools. Test automation covers 17 out of the 86 success criteria in the WCAG 2.2. However, test automation tools are not capable of thorough evaluation that would meet the WCAG set standard for some of these 17 success criteria. 

    Sufficiently evaluating conformance requires an accessibility specialist evaluation which is a tedious process, as web pages are more complicated than ever. Semi-automated accessibility evaluation tools help evaluators by guiding them through the most common accessibility barriers found on web pages. However, manual evaluation can end up with a different outcome depending on the evaluator's knowledge and workmanship.
    
\begin{itemize}
    \item \textbf{RQ2.} How does Generative AI assist in addressing these limitations?
\end{itemize}

    Generative AI can be utilized to address these limitations. This study shows that Large Language Models (LLM) can assist evaluators in conformance checks on the page title that require a thorough understanding of the content. However, a more detailed observation shows that the LLM had fallacies in how it ended up with the correct outcome when conducting a conformance evaluation for the failing ACT cases. On pages with more content, the outcome of the LLM could speed up the conformance evaluation process. However, as results show, with a zero-shot chain of thought prompting, LLMs are not capable of reliably determining inapplicability.

\section{Study result analysis}

This study shows that even though legislation is moving forward in regards to accessibility, the nature of accessibility and accessibility evaluation is complex, and requires expertise from designers, developers, quality assurance, and accessibility reviewers. An accessibility specialist needs to have a thorough knowledge of the WCAG documents, as no automated or semi-automated accessibility evaluation tool has 100\% coverage. In addition, web developers, designers, and content creators ought to study the same WCAG documents.

An accessibility evaluation tool developer has to understand the ACT rules and sufficient techniques used to check for conformance, as well as how browsers work, to develop a reliable and robust tool for accessibility evaluators. Transparency of evaluation tools helps the evaluator understand which success criteria it covers and to what extent. The study shows that Large Language Models can be utilized to improve the sufficiency of the accessibility evaluation and help ease the conformance evaluation process when using semi-automated accessibility evaluation tools. However, the output of the LLM should be evaluated by a human on how it ended up to the conclusion. Therefore, an LLM would be an additional asset in AETs when conducting conformance evaluations.

\subsection{Prompt iteration}

These results build on existing evidence that LLMs are good zero-shot reasoners \citep{kojima2023large}. With rigorous prompt iteration, the accuracy and quality of the outcome improved. By evaluating the outcome of the LLM, patterns can be detected where the LLM fails to provide reasoning for checks it performed, giving possible directions for improvements. An example observed in this study between the iterations is the order of the conditional checks the LLM should take into account. Therefore, an imperative approach to how the LLM should operate step by step combined with the zero-shot chain of thought improved the quality of the outcome. However, as the second iteration of the artifact went through multiple changes, it remains unknown if \textcite{kojima2023large} zero-shot chain of thought change, or moving the fourth rule as a separate sentence, affected the accuracy and consistency in this study.

\section{Limitations}

The lack of a thorough evaluation, such as surveys or interviews with potential users of this artifact, is a concern of the validity of this study. The evaluation of usefulness is solely based on the observations of the thesis writer. The artifact is a proof of concept and has not been evaluated by accessibility evaluators for usefulness in accessibility conformance reviews. Therefore, a proof of suitability, evaluating whether the LLM would assist and speed up conformance reviews, is yet to be evaluated that would support the findings of the study. 

Two concerns regarding the chosen LLM are that this study was solely done using the ChatGPT 3.5 user interface due to it being free to use and that the LLM is a closed-source tool. Therefore, between the iterations, there is no knowledge if there have been any improvements made by OpenAI to the language model. However, according to OpenAI, the ChatGPT 3.5 model was trained only with data available in early 2022 \citep{openai_35}. Therefore, it can be assumed that the test cases available at \textcite{act_rule_g88} should not be part of the LLM knowledge base. The replication of this study should be straightforward with different LLMs, such as the new GPT-4o, which was announced in September 2024 and is now the main model provided to free-tire users of OpenAI.

Additionally, the characteristics of LLMs, such as non-deterministic output given the same input, or the limited amount of characters that you can input, are a threat to the external validity of the study. This study was conducted using very short code snippets, therefore no input limits were hit. Even though, in the second iteration all the passing and failing test case sequences were correctly evaluated by the LLM, this does not guarantee that the LLM would always correctly evaluate due to the characteristics of LLM being non-deterministic. However, a better design could reduce the input limitation threat. For example, in this study setting, parsing the HTML code, picking the first title element encountered, and the content within the HTML body or main tag would significantly reduce the number of characters sent to the LLM. In addition, the non-deterministic behavior would cause problems if your accessibility evaluation tool promises zero false positives when evaluating for accessibility.

It is beyond the scope of this study to evaluate how the LLM would work if the website language were other than English, or with other large language models available, either provided by some entity online or running the models locally.

\section{Future research}

Future studies should take into account the language used on the website, as accessibility barriers are not only limited to English, specifically, to low-resource languages that have less data available to train the LLMs. In addition, as this study was limited to the short ACT cases, a case study where the artifact would be implemented into a semi-automatic accessibility evaluation tool with a feedback loop from the evaluator would provide insight into how the LLM evaluates more complex websites with more content, and how LLMs could improve the efficiency of the conformance review. Additionally, as conformance reviews are a tedious process, automated ways to measure and observe the output of an LLM's effectiveness and trustworthiness for success criteria evaluations would grow the coverage of automated accessibility evaluation tools.

