\chapter{Conclusions\label{conclusions}}

The goal of this study was to find out how sufficiently current accessibility evaluation tools test the WCAG 2.2 success criteria and to assess the potential of Large Language Models in these tools during conformance evaluation. It is suggested to use multiple semi-automated and automated accessibility evaluation tools during conformance evaluation to improve the coverage of found accessibility barriers. The findings show that, when given conditions to check for in the prompt, LLMs can assist in that the HTML code has a title, the title is relevant to the page content, and the title identifies the page. However, a human should evaluate the correctness of the output. Additionally, an accessibility conformance evaluator does not necessarily need to be a subject matter expert regarding website content, as an LLM could help evaluate the context based criteria. Integrating Generative AI, such as LLMs, into AETs could enhance the accuracy and efficiency of conformance evaluation, enabling accessibility reviewers to carry out more comprehensive accessibility assessments more easily.


