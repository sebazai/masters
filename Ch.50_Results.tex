\chapter{Results\label{results}}

This chapter presents the results and answers the research questions. Section \ref{rq1_result} answers the first research question. In Section \ref{rq2_result} the outcome of the LLM is analyzed for each iteration based on the evaluation criteria. In the last section, the artifact is studied from the perspective if it could be used in other possible success criteria and ACT rules provided by W3C.

\section{Limitations of web accessibility evaluation tools\label{rq1_result}}

The literature review done in Chapter \ref{accessibility_evaluation} answers RQ1. In total, there are 86 success criteria in the WCAG 2.2 documents. Out of these 86 success criteria, test automation covers only 17 reliably (zero false positives). Using manual evaluation with semi-automated web accessibility evaluation tools increases the coverage, and adds to the sufficiency of these 17 found by automation \citep{dequecoverage_semi}.

Papers on Automated AETs show that there is a significant distribution of the amount of found accessibility barriers on the same page \citep{comparison_10.1145/3371300.3383346, tool_analysis_directive}. Studies conducted point out that even experts evaluating the same page can end up with different results \citep{10.1145/1878803.1878813_testability_expertise}. Additionally, the transparency of results by AETs to accessibility evaluators even further adds to the complexity of interpreting which success criteria have been sufficiently evaluated.

Semi-automated web accessibility evaluation tools help in conformance evaluation by guiding the evaluator with wizards to further increase coverage \citep{dequecoverage_semi}. However, the outcome of the final evaluation is subjective to the evaluator \citep{10.1145/1878803.1878813_testability_expertise}. To fully conform with some of the success criteria requires knowledge of the context of the web page. Therefore, expertise matters when evaluating web pages for conformance using semi-automated AETs.

\section{Capabilities of LLM's for Page Titled evaluation\label{rq2_result}}

This section describes the outcomes of the artifact and answers RQ2. Some of the success criteria have context-based evaluation metrics, such as 2.4.2 Page Titled success criterion. The results show that Large Language Model is capable of assisting in a conformance evaluation when evaluating the context based success criterion 2.4.2 Page Titled. However, a more detailed look on how it ended up with the correct outcome shows discrepancy.

\begin{table}[]
\centering
\caption{Table summarizing the overall result whether the LLM succeeded in the conformance evaluation.}
\label{table:result_summary}
\begin{tabular}{|l|cc|cc|cc|cc|cc|cc|cl|}
\hline
Test case  & \multicolumn{2}{c|}{P1}    & \multicolumn{2}{c|}{P2}    & \multicolumn{2}{c|}{P3}    & \multicolumn{2}{c|}{F1}    & \multicolumn{2}{c|}{F2}    & \multicolumn{2}{c|}{F3}    & \multicolumn{2}{c|}{I1}    \\ \hline
Iteration  & \multicolumn{1}{c|}{1} & 2 & \multicolumn{1}{c|}{1} & 2 & \multicolumn{1}{c|}{1} & 2 & \multicolumn{1}{c|}{1} & 2 & \multicolumn{1}{c|}{1} & 2 & \multicolumn{1}{c|}{1} & 2 & \multicolumn{1}{c|}{1} & 2 \\ \hline
Sequence 1 & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{}  & \cmark & \multicolumn{1}{c|}{}  & \cmark & \multicolumn{1}{c|}{} & \cmark & \multicolumn{1}{c|}{\cmark} &   \\ \hline
Sequence 2 & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{}  & \cmark \\ \hline
Sequence 3 & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark \\ \hline
Sequence 4 & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{}  & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{}  &   \\ \hline
Sequence 5 & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{}  & \cmark & \multicolumn{1}{c|}{}  & \cmark & \multicolumn{1}{c|}{\cmark} & \cmark & \multicolumn{1}{c|}{}  &   \\ \hline
\end{tabular}
\end{table}

In both iterations of the artifact, the passing test cases P1, P2 and P3 were the most consistent, accurate, and useful. The LLM did not suggest any improvements for the ACT passing test cases, as each sequence was correctly evaluated and already had a descriptive title present. 

The LLM had issues evaluating the test cases F1 and F2 in the first iteration. The second iteration outcome showed improvements in the conformance evaluation, see Table \ref{table:result_summary}. However, even though the second iteration explicitly states partial conformance for the F1 and F2 test cases in the outcome, how the LLM ended up to this conclusion had fallacies. In both iterations, out of the 30 sequences, there were only two output sequences (F1-1-1 and F1-1-5) that did not suggest an improved title for the page. The F3 test case did not cause major problems for the LLM.

In both iterations of the artifact, only two inapplicable sequences were evaluated correctly, therefore the evaluation outcome can not be relied upon.

Each iteration is analyzed in its own subsection in more detail. Iteration results are evaluated more deeply based on usefulness, accuracy, and consistency. See Appendix \ref{appendix:iterations} for actual outputs.

\subsection{First iteration}

The LLM was capable of evaluating if the title was descriptive based on the content of the web page. However, problems occurred in failing and inapplicable test cases. Passing test cases had a successful outcome based on our evaluation criteria, whereas failing and inapplicable test cases had a variance in consistency and fallacies in reasoning.

\subsubsection{Passed test cases}

When assessing the output in detail for usefulness, the LLM provides reasoning for each four of the rules in the input. However, the P2 test case's fourth sequence (P2-1-4) states that the code snippet has only one title element, even though the test case has two. 

In the P3 test case, it can be noted that the LLM is not capable of identifying correctly where the title element is present, and in three out of five sequences, it falsely states that the title element is within the head section of the HTML document, even though it is in the body section. However, this is a minor mistake, as most browsers can fix and set the title correctly.

The accuracy of the accessibility evaluation is described in a short paragraph at the end of the output for all the test cases. Each test case and its sequences have the same outcome from a contextual perspective, therefore the LLM is accurate and consistent when evaluating these passed test cases.

\subsubsection{Failing test cases}

Inconsistency and inaccuracy are observed in the failing test cases F1 and F2 sequences. Additionally, the usefulness of the outcome is not at an appropriate leave as the reasoning has fallacies. However, the F3 test case sequence outcomes did not have similar problems as in test cases F1 and F2.

\subsubsection{F1}

F1-1-2, F1-1-3, and F1-1-4 have the correct outcome where the LLM states partial conformance. Additionally, those sequences that succeed in evaluating conformance correctly also provide suggestions for improvement. 

The first sequence (F1-1-1) has problems to understand that the whole web page code is provided. In the outcome, there is no mention of clementines being the correct context of the page. Additionally, the same uncertainty of what the LLM is evaluating can be understood from the last paragraph which seems to state conformance:

\blockquote{Overall, based on the provided HTML code and the given web accessibility rules, the web page appears to conform with the criteria. However, further evaluation within the context of the entire website and user experience might be necessary for a comprehensive assessment.}

In the fifth sequence (F1-1-5), the LLM explicitly indicates that the page conforms with the 2.4.2 Page Titled success criterion. In addition, the LLM seems to provide an irrational conclusion for the second rule \textit{Check that the title is relevant to the content of the Web page} with an output of:

\blockquote{The title of the web page is "Apple harvesting season". This title seems relevant to the content of the page, which discusses the harvest timing of clementines, a type of fruit.}

\subsubsection{F2}

The F2 test case with two titles, see Figure \ref{failing_cases}, where the first one is incorrect and the second one is correct causes issues to the conformance evaluation made by the LLM. In regards to accuracy, the LLM states conformance in three out of the five sequences. Therefore, three out of five fail to provide an accurate conformance evaluation as F2 is a test case that has partial conformance.

A closer look at the three not correctly evaluated test sequences indicates that the existence of two titles on the web page code, and the fourth rule pointing out to use the first encountered title causes problems for reasoning, see Figure \ref{first_iteration} for the four rules. The LLM finds the second title on the web page and uses it to evaluate conformance for the first three rules. This ordering of rules causes problems to the LLM, indicating that the scope of the fourth rule is not in a logical order.

Below is an example from F2-1-4 output from the LLM on the fourth rule reasoning, which is similar in all three not correctly evaluated cases (F2-1-1, F2-1-4 and F2-1-5): \blockquote{Since browsers typically recognize only the first title element, and in this case, the relevant title is the second one, it aligns with the rule.}. The LLM evaluated the conformance using the second title even thought the rule explicitly said to do the evaluation based on the first title found in the HTML code.

Due to the possible problems described above, the accuracy for this test case is not on a sufficient level, nor the consistency. Therefore, the output that the LLM provided for evaluating conformance has fallacies. However, in each sequence the LLM points out that the second title would be more relevant.

\subsubsection{F3}

All, except the first sequences (F3-1-1), the answer is consistent and all outcomes accurately state partial conformance and provide suggestions on how to improve the title description. The partial conformance from each outcome is based on the first and fourth rule of the input artifact. In other words, the web page has a title and there is only one title present. 

However, the first sequence ends with \blockquote{Overall, while the web page meets the basic requirement of having a title, it could improve its accessibility by making the title more descriptive and directly relevant to the content, such as "Search results for 'accessibility' at University of Arkham".}, indicating that the test case passed the conformance evaluation, but the title could be improved.

\subsubsection{Inapplicable test case (I1)}

In only two of the sequences, it was able to indicate that the page should not be evaluated as it does not have a proper HTML structure as the title tag is used to describe the SVG element. On other test sequences, it satisfied the success criterion. However, as this is a zero-shot prompt there are no examples of how to determine applicability or inapplicability. Therefore, the outcome of the sequences that try to evaluate this inapplicable test case is of limited use if the accuracy can not be improved.

\subsection{Second iteration}

The improvements done in the second iteration of the artifact had a significant effect on the outcome of failing test cases. With the removal of the fourth rule and using it as a separate instruction in the artifact, the usefulness, accuracy, and consistency increased.

\subsubsection{Passed test cases}

In regards to accuracy, all sequences within the passing test cases were evaluated correctly. Therefore, each test case sequence was consistent in regard to accuracy.

Logical reasoning in each outcome on how it evaluated conformance is provided by the LLM. Therefore, the artifact and the outcome is useful for the evaluator. As in the first iteration of the artifact, the LLM still had issues identifying in the P3 test case that the title element is not within the head section. As earlier stated in the first iteration results, this is a minor flaw that does not affect the result when the descriptive title is within the body tag.

\subsubsection{Failing test cases}

In comparison to the first iteration of the artifact, significant improvements in overall accuracy can be identified for the failing test cases. Accuracy and consistency improvements are distinguished from the outputs, as each sequence outcome is perceived as partial conformance. 

\subsubsection{F1}

Each of the five sequence ends up in partial conformance. Partial conformance is based on the first rule passing, that is, the web page has a title. One sequence (F1-2-2) stood out in the results, where there is a difference to the other sequences. The F1-2-2 states that it conforms with the third rule where it should check that the web page can be identified by the title \blockquote{Apple harvesting season}, even though the content is about clementines. However, all except the second sequence (F1-2-2) have similar contextual output, where the first rule is met, but the second and third rule fails, ending up in partial conformance.

\subsubsection{F2}

The expected result is that the partial conformance should come out of the second and third condition to check for, as the first title is not relevant to the page content and the title does not identify the web page. 

The input artifact explicitly states the following: \blockquote{The scope of given web accessibility rules are limited to only checking the first title element in a web page.}. However, within each of the outcome the LLM has used second title \blockquote{Clementine harvesting season} in assessing conformance. However, all of them end up in partial conformance due to either second or third condition is evaluated based on the first title found. Additionally, it can be observed that the second title is always mentioned as a better option for the page title from the LLM output detail of the third rule.

Overall, in terms of accuracy and consistency, each outcome states partial conformance that is described in the last paragraph of each outcome. However, the LLM neglects the information that it should only be evaluating the first found title.

\subsubsection{F3}

A direct quote from one of the sequences summarizes the results very well: \blockquote{Overall, while the page meets the first criterion by having a title, it falls short of the other two criteria as the title isn't directly relevant to the content and may not effectively identify the page.}. Therefore, consistency and accuracy are spot on. Additionally, in each sequence, the reasoning for the outcome is similar and the LLM suggests either explicitly or implicitly a more descriptive title for the test case.

\subsubsection{Inapplicable test case (I1)}

Only the second and third sequence indicates successful evaluation for inapplicability as there is no title element for the whole web page, rather the title element is for the SVG element. For example, the first check that the web page has a title is evaluated in the following way: \blockquote{The web page contains a <title> element within the <svg> tag. However, the <title> element is intended for providing a title for the SVG graphic for accessibility purposes, not for the entire web page}.

\subsection{Generalization}

In Design Science Research Methodologies, the generalization of the artifact is important. Generalization is evaluated on how well the artifact works in other similar contexts \citep{design_science_eval}. This section evaluates the possibility of using the artifact for other conformance-checking techniques provided in the WCAG documents.

In its current form, as a proof of concept, the possibility of using the artifact for other ACT rules is limited because the input prompt is specifically tailored to test if the web page title is descriptive. The artifact is a proof of concept on how LLM evaluates accessibility using the technique provided by \textcite{g88} and modified accessibility support information from \textcite{act_rule_g88}. 

By incorporating the input prompt in a semi-automated accessibility evaluation tool, placeholders in the input prompt could be utilized, therefore improving the generalization of the artifact. However, the artifact works as "the code" for the LLM, and a small change can have a significant change in the quality of the output, as demonstrated in this study. Therefore, placeholders, choice of words, and small changes in the input prompt require thorough testing and evaluation.

Furthermore, currently, the artifact is not tied to any specific accessibility evaluation tool. The input artifact could be used by any organization and in other Large Language Models, as the input prompt was the artifact iterated upon.

To conclude the generalization, the artifact has potential to be used in other contexts, as the rules could be easily swapped with other ACT rules for other success criteria, and the custom sentence on picking the first title found could be an additional placeholder.
