@inproceedings{10.1145/3594806.3596542,
author = {Othman, Achraf and Dhouib, Amira and Nasser Al Jabor, Aljazi},
title = {Fostering websites accessibility: A case study on the use of the Large Language Models ChatGPT for automatic remediation},
year = {2023},
isbn = {9798400700699},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594806.3596542},
doi = {10.1145/3594806.3596542},
abstract = {The use of automated accessibility testing tools remains a common practice for evaluating web accessibility. However, the results obtained from these tools may not always provide a comprehensive and complete view of a site's accessibility status. The main purpose of this study is to improve web accessibility by automatically remediating non-accessible ones using Large Language Models (LLM), particularly ChatGPT. The effectiveness of the used model in detecting and remediating accessibility issues to ensure compliance with the Web Content Accessibility Guidelines (WCAG 2.1) is also discussed. By using ChatGPT as a remediation tool, this study investigates the potential of LLM in improving web accessibility. In the case study, two websites that did not adhere to the WCAG 2.1 guidelines were selected as the primary experimental subjects for the study. These websites were assessed using the web accessibility evaluation tool, WAVE, to detect accessibility issues. The identified issues served then as the basis for remediation using ChatGPT. The effectiveness of the used advanced language model as a web accessibility remediation tool was evaluated by comparing its findings with those obtained from manual accessibility testing. The results of this comparison have significant implications for stakeholders involved in achieving WCAG compliance and contribute to the development of more accessible online platforms for individuals with disabilities.},
booktitle = {Proceedings of the 16th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {707–713},
numpages = {7},
location = {Corfu, Greece},
series = {PETRA '23}
}

@book{webaccessibility,
Abstract = {Covering key areas of evaluation and methodology, client-side applications, specialist and novel technologies, along with initial appraisals of disabilities, this important book provides comprehensive coverage of web accessibility. Written by leading experts in the field, it provides an overview of existing research and also looks at future developments, providing a much deeper insight than can be obtained through existing research libraries, aggregations, or search engines.},
Author = {Yeliz, Yesilada and Simon, Harper},
ISBN = {9781447174394},
Publisher = {Springer},
Series = {Human–Computer Interaction Series},
Title = {Web Accessibility : A Foundation for Research.},
Volume = {2nd ed. 2019},
URL = {https://search.ebscohost.com/login.aspx?direct=true&amp;db=nlebk&amp;AN=2153923&amp;site=ehost-live&amp;scope=site},
Year = {2019},
}
@online{openai_35,
    author    = {{OpenAI}},
    title     = "Introducing ChatGPT",
    url       = "https://openai.com/index/chatgpt/",
    note = "Accessed: 04.09.2024",
    year = 2024
}

@online{etsi_standard,
    author    = {{ETSI}},
    title     = "EN 301 549 V3 the harmonized European Standard for ICT Accessibility",
    url       = "https://www.etsi.org/human-factors-accessibility/en-301-549-v3-the-harmonized-european-standard-for-ict-accessibility",
    note = "Accessed: 07.04.2024",
    year = 2024
}


@online{whodisability,
    author    = {World Health Organization {WHO}},
    title     = "Disability",
    url       = "https://www.who.int/news-room/fact-sheets/detail/disability-and-health",
    urldate = {2024-02-05},
    year = 2023
}

@online{whovision,
    author    = {World Health Organization {WHO}},
    title     = "Blindness and vision impairment",
    url       = "https://www.who.int/news-room/fact-sheets/detail/blindness-and-visual-impairment",
    urldate = {2024-04-16},
    year = 2023
}


@online{webaccessibilitydefinition,
    author    = {{Regional State Administrative Agency}},
    title     = "Accessibility overview",
    url       = "https://www.webaccessibility.fi/accessibility-overview/",
    note = "Accessed: 05.02.2024",
    year = "2023"
}

@online{eudirective2016,
    author    = {{Directive 2016/2102}},
    title     = "Directive (EU) 2016/2102 of the European Parliament and of the Council of 26 October 2016 on the accessibility of the websites and mobile applications of public sector bodies",
    url       = "https://eur-lex.europa.eu/eli/dir/2x016/2102/oj",
    note = "Accessed: 07.02.2024",
    year = "2016"
}

@online{eudirective2019,
    author    = {{Directive 2019/882}},
    title     = "Directive (EU) 2019/882 of the European Parliament and of the Council of 17 April 2019 on the accessibility requirements for products and services",
    url       = "https://eur-lex.europa.eu/eli/dir/2019/882/oj",
    note = "Accessed: 06.02.2024",
    year = "2019"
}

@online{w3cbarriers,
    author    = {Shadi Abou-Zahra},
    title     = "Diverse Abilities and Barriers",
    url       = "https://www.w3.org/WAI/people-use-web/abilities-barriers/",
    note = "Accessed: 16.04.2024",
    year = "2017"
}

@online{waiaria,
    author    = "James Nurthen and Michael Cooper and Shawn Lawton Henry",
    title     = "WAI-ARIA Overview",
    url       = "https://www.w3.org/WAI/standards-guidelines/aria/",
    note = "Accessed: 17.04.2024",
    year = "2024"
}

@online{wcagadoptioneurope,
    author    = {Shadi Abou-Zahra},
    title     = "WCAG 2.1 Adoption in Europe",
    url       = "https://www.w3.org/blog/2018/wcag-2-1-adoption-in-europe/",
    note = "Accessed: 07.02.2024",
    year = "2018"
}

@online{eudirectivemonitoring,
    author    = {{The European Commission}},
    title     = "establishing a monitoring methodology and the arrangements for reporting by Member States in accordance with Directive (EU) 2016/2102 of the European Parliament and of the Council on the accessibility of the websites and mobile applications of public sector bodies",
    url       = "https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:32018D1524",
    note = "Accessed: 05.02.2024",
    year = "2018"
}

@online{wcagoverview,
    author    = {Shawn Lawton Henry},
    title     = "WCAG 2 Overview",
    url       = "https://www.w3.org/WAI/standards-guidelines/wcag/",
    note = "Accessed: 26.02.2024",
    year = "2023"
}

@online{wcag22,
    author    = "Alastair Campbell and Chuck Adams and Rachael Bradley Montgomery and Michael Cooper and Andrew Kirkpatrick",
    title     = "Web Content Accessibility Guidelines (WCAG) 2.2",
    url       = "https://www.w3.org/TR/WCAG22/",
    note = "Accessed: 27.02.2024",
    year = "2023"
}

@online{wcag_checklist,
    author    = "Eric Eggert",
    title     = "How to Meet WCAG (Quick Reference)",
    url       = "https://www.w3.org/WAI/WCAG22/quickref/?currentsidebar=%23col_customize&showtechniques=111&levels=aaa&techniques=advisory&technologies=js%2Cserver%2Csmil%2Cpdf",
    note = "Accessed: 07.04.2024",
    year = "2023"
}



@online{wcagevaluationtools,
    author    = "Vera Lange and Kevin White and Michel Hansma",
    title     = "Selecting Web Accessibility Evaluation Tools",
    url       = "https://www.w3.org/WAI/test-evaluate/tools/selecting/",
    note = "Accessed: 05.03.2024",
    year = "2024"
}

@online{govukaccessibility,
    author    = "Mehmet Duran and Alistair Duggin and Richard Morton",
    title     = "What we found when we tested tools on the world’s least-accessible webpage",
    url       = "https://accessibility.blog.gov.uk/2017/02/24/what-we-found-when-we-tested-tools-on-the-worlds-least-accessible-webpage/",
    note = "Accessed: 05.03.2024",
    year = "2017"
}

@online{govukaccessibilityresults,
    author    = "Mehmet Duran and Alistair Duggin and Richard Morton",
    title     = "Accessibility tools audit results - Results - GDS accessibility team",
    url       = "https://alphagov.github.io/accessibility-tool-audit/index.html",
    note = "Accessed: 06.03.2024",
    year = "2018"
}

@online{govukaccessibilityresults_blog,
    author    = "Mehmet Duran",
    title     = "What we found when we tested tools on the world’s least-accessible webpage",
    url       = "https://accessibility.blog.gov.uk/2017/02/24/what-we-found-when-we-tested-tools-on-the-worlds-least-accessible-webpage/",
    note = "Accessed: 07.04.2024",
    year = "2017"
}


@online{dequecoverage,
    author    = {{Deque Systems}},
    title     = "The Automated Accessibility Coverage Report",
    url       = "https://accessibility.deque.com/hubfs/Accessibility-Coverage-Report.pdf",
    note = "Accessed: 06.03.2024",
    year = "2021"
}

@online{dequecoverage_semi,
    author    = {{Deque Systems}},
    title     = "The Semi-Automated Accessibility Testing Coverage Report",
    url       = "https://accessibility.deque.com/hubfs/Semi-Automated-Accessibility-Testing-Coverage-Report.pdf",
    note = "Accessed: 10.04.2024",
    year = "2022"
}



@online{dequeaxe4_5,
    author    = "Wilco Fiers",
    title     = "Axe-core 4.5: First WCAG 2.2 Support and More",
    url       = "https://www.deque.com/blog/axe-core-4-5-first-wcag-2-2-support-and-more/",
    note = "Accessed: 07.03.2024",
    year = "2023"
}


@online{webaimmillions,
    author    = "WebAIM",
    title     = "The 2024 report on the accessibility of the top 1,000,000 home pages",
    url       = "https://webaim.org/projects/million/",
    note = "Accessed: 17.04.2024",
    year = "2024"
}


@online{wcagact,
    author    = "Shadi Abou-Zahra and Shawn Lawton Henry",
    title     = "Accessibility Conformance Testing (ACT) Overview",
    url       = "https://www.w3.org/WAI/standards-guidelines/act/",
    note = "Accessed: 04.03.2024",
    year = "2020"
}

@online{wcag_page_titled,
    author    = "Alastair Campbell and Charles Adams and Rachael Bradley Montgomery",
    title     = "Understanding Success Criterion  2.4.2: Page Titled | WAI | W3C",
    url       = "https://www.w3.org/WAI/WCAG22/Understanding/page-titled.html",
    note = "Accessed: 29.04.2024",
    year = "2024"
}

@online{g88,
    author    = "Alastair Campbell and Charles Adams and Rachael Bradley Montgomery",
    title     = "G88: Providing descriptive titles for Web pages | WAI | W3C",
    url       = "https://www.w3.org/WAI/WCAG22/Techniques/general/G88",
    note = "Accessed: 29.04.2024",
    year = "2024"
}

@online{act_rule_g88,
    author    = "Anne Thyme Nørregaard and Corbb O'Connor",
    title     = "HTML page title is descriptive | ACT Rule | WAI | W3C",
    url       = "https://www.w3.org/WAI/standards-guidelines/act/rules/c4a8a4/",
    note = "Accessed: 29.04.2024",
    year = "2023"
}

@online{svg_title,
    author    = {{Mozilla Foundation}},
    title     = "<title> — the SVG accessible name element",
    url       = "https://developer.mozilla.org/en-US/docs/Web/SVG/Element/title",
    note = "Accessed: 20.08.2024",
    year = "2024"
}



@online{web_accessibility_specialist,
    author    = {{International Association of Accessibility Professionals}},
    title     = "Web Accessibility Specialist | International Association of Accessibility Professionals",
    url       = "https://www.accessibilityassociation.org/s/wascertification",
    note = "Accessed: 11.05.2024",
    year = "2024"
}

@misc{kojima2023large,
      title={Large Language Models are Zero-Shot Reasoners}, 
      author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
      year={2023},
      eprint={2205.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@online{deque_igt,
    author    = "Deque",
    title     = "Intelligent Guided Tests | Deque Docs",
    url       = "https://docs.deque.com/devtools-for-web/4/en/devtools-igt",
    note = "Accessed: 02.05.2024",
    year = "2024"
}

@online{boia_improve_accessibility,
    author    = {{Bureau of Internet Accessibility}},
    title     = "3 Ways That Artificial Intelligence Can Improve Web Accessibility",
    url       = "https://www.boia.org/blog/3-ways-that-artificial-intelligence-can-improve-web-accessibility",
    note = "Accessed: 02.05.2024",
    year = "2023"
}

@online{boia_alt_text,
    author    = {{Bureau of Internet Accessibility}},
    title     = "Be Careful When Using A.I. for Alternative Text",
    url       = "https://www.boia.org/blog/be-careful-when-using-ai-for-alternative-text",
    note = "Accessed: 02.05.2024",
    year = "2023"
}

@online{ai_wcag_email,
    author    = "Alastair Campbell",
    title     = "Re: AI and the future of Web accessibility Guidelines from Alastair Campbell on 2024-04-19 (w3c-wai-gl@w3.org from April to June 2024)",
    url       = "https://lists.w3.org/Archives/Public/w3c-wai-gl/2024AprJun/0043.html",
    note = "Accessed: 02.05.2024",
    year = "2024",
    month = "April"
}

@online{potential_for_ai,
    author    = "Aaron Gustafson",
    title     = "Opportunities for AI in Accessibility – A List Apart",
    url       = "https://alistapart.com/article/opportunities-for-ai-in-accessibility/",
    note = "Accessed: 02.05.2024",
    year = "2024",
    month = "February"
}

@online{accessibility_and_ai,
    author    = "Joe Dolson",
    title     = "Accessibility and Artificial Intelligence - Joe Dolson Web Accessibility",
    url       = "https://www.joedolson.com/2023/06/accessibility-and-artificial-intelligence/",
    note = "Accessed: 02.05.2024",
    year = "2023",
    month = "June"
}


@online{accessibility_evaluation_experts,
    author    = "Giorgio Brajnik and Simon Harper and Yeliz Yesilada",
    title     = "How much does expertise matter?: a barrier walkthrough study with experts and non-experts",
    url       = "https://doi.org/10.1145/1639642.1639678",
    note = "Accessed: 11.03.2024",
    year = "2009"
}

@online{tool_list,
    author    = "W3C Web Accessibility Initiative WAI",
    title     = "Web Accessibility Evaluation Tools List",
    url       = "https://www.w3.org/WAI/test-evaluate/tools/list/",
    note = "Accessed: 18.03.2024",
    year = "2024"
}


@online{act_overview,
    author    = "Shadi Abou-Zahra and Shawn Lawton Henry",
    title     = "Accessibility Conformance Testing (ACT) Overview",
    url       = "https://www.w3.org/WAI/standards-guidelines/act/",
    note = "Accessed: 18.03.2024",
    year = "2020"
}

@inproceedings{tool_analysis_directive,
author = {Rajh, Nata\v{s}a and Debevc, Matja\v{z}},
title = {Analysis of web accessibility evaluation tools and guidelines for monitoring according to the Directive (EU) 2016/2102},
year = {2023},
isbn = {9781450398077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563137.3563148},
doi = {10.1145/3563137.3563148},
abstract = {This paper presents a comparative analysis of automated web accessibility assessment tools and guidelines for monitoring of public websites and reporting according to the Directive (EU) 2016/2102. A review of previous research and our own comparative analysis revealed that the tools differ not only in functionality and result presentation, but also in violation discovery. Overviews of the Web Accessibility Directive Expert Group meetings` minutes and first reports by the European member states showed that unified monitoring and reporting do not exist between member states. We provided guidelines that would meet the minimum requirements of the Commission Implementing Decision (EU) 2018/1524, as well as guidelines for more detailed evaluation, which would improve results in terms of providing a clearer picture of the actual level of accessibility and enable efficient comparison between European member states.},
booktitle = {Proceedings of the 10th International Conference on Software Development and Technologies for Enhancing Accessibility and Fighting Info-Exclusion},
pages = {195–202},
numpages = {8},
keywords = {accessibility Directive, accessibility monitoring, web accessibility, web accessibility evaluation tools},
location = {Lisbon, Portugal},
series = {DSAI '22}
}

@inproceedings{benchmark_aet,
author = {Vigo, Markel and Brown, Justin and Conway, Vivienne},
title = {Benchmarking web accessibility evaluation tools: measuring the harm of sole reliance on automated tests},
year = {2013},
isbn = {9781450318440},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2461121.2461124},
doi = {10.1145/2461121.2461124},
abstract = {The use of web accessibility evaluation tools is a widespread practice. Evaluation tools are heavily employed as they help in reducing the burden of identifying accessibility barriers. However, an over-reliance on automated tests often leads to setting aside further testing that entails expert evaluation and user tests. In this paper we empirically show the capabilities of current automated evaluation tools. To do so, we investigate the effectiveness of 6 state-of-the-art tools by analysing their coverage, completeness and correctness with regard to WCAG 2.0 conformance. We corroborate that relying on automated tests alone has negative effects and can have undesirable consequences. Coverage is very narrow as, at most, 50\% of the success criteria are covered. Similarly, completeness ranges between 14\% and 38\%; however, some of the tools that exhibit higher completeness scores produce lower correctness scores (66-71\%) due to the fact that catching as many violations as possible can lead to an increase in false positives. Therefore, relying on just automated tests entails that 1 of 2 success criteria will not even be analysed and among those analysed, only 4 out of 10 will be caught at the further risk of generating false positives.},
booktitle = {Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility},
articleno = {1},
numpages = {10},
keywords = {tools, testing, evaluation, benchmark, accessibility, WCAG},
location = {Rio de Janeiro, Brazil},
series = {W4A '13}
}

@inproceedings{comparison_10.1145/3371300.3383346,
author = {Fraz\~{a}o, T\^{a}nia and Duarte, Carlos},
title = {Comparing accessibility evaluation plug-ins},
year = {2020},
isbn = {9781450370561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3371300.3383346},
doi = {10.1145/3371300.3383346},
abstract = {This article reports the results of a study comparing evaluation accessibility plugins extensions for the Chrome web browser. Eight of the most well-known tools among developers were chosen. All tools are free or available under an open-source license, and work with the Chrome browser. The tools were compared based on their feature set, their usability and their evaluation results of ten of the Alexa top websites. We found that individual tools still provide limited coverage of the success criteria; the coverage of success criteria varies quite a lot from evaluation engine to evaluation engine; what are the most and least covered success criteria in automated evaluations. After analysing the results, we highly recommend to use more than one tool (with a different engine) and to complement automated evaluation with manual checking.},
booktitle = {Proceedings of the 17th International Web for All Conference},
articleno = {20},
numpages = {11},
keywords = {tools, evaluation, automatic, accessibility},
location = {Taipei, Taiwan},
series = {W4A '20}
}

@article{ouyang2023llm,
  title={LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation},
  author={Ouyang, Shuyin and Zhang, Jie M and Harman, Mark and Wang, Meng},
  journal={arXiv preprint arXiv:2308.02828},
  year={2023}
}

@online{power_determinism,
    author    = "Boris Power",
    title     = "A question on determinism - API - OpenAI Developer Forum",
    url       = "https://community.openai.com/t/a-question-on-determinism/8185",
    note = "Accessed: 06.05.2024",
    year = "2021",
    month = "August"
}



@article{white2023prompt,
  title={A prompt pattern catalog to enhance prompt engineering with chatgpt},
  author={White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C},
  journal={arXiv preprint arXiv:2302.11382},
  year={2023}
}


@inproceedings{comparison_10.1145/3607720.3607722,
author = {Chadli, Fatima Ezzahra and Gretete, Driss and Moumen, Aniss},
title = {Comparison of Free and Open Source WCAG Accessibility Evaluation Tools},
year = {2023},
isbn = {9798400700194},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607720.3607722},
doi = {10.1145/3607720.3607722},
abstract = {Access to the internet is essential to any individual, including people with disabilities that encounter many challenges and obstacles while browsing the Web. To tackle those problems, the Web Accessibility Initiative (WAI) [1], since its creation in 1997, has worked on improving accessibility of the Web for people with disabilities by providing guidelines (WCAG) and tools for Web Accessibility Assessments. This study aims to compare free and open-source tools from the official (W3C) list of WAETs for evaluating websites against the Web Content Accessibility Guidelines (WCAG) 2.1 standards [2]; the comparison is based on the coverage error ratio (CER) metric that compares the performance of WAETs in identifying Web accessibility problems.},
booktitle = {Proceedings of the 6th International Conference on Networking, Intelligent Systems \& Security},
articleno = {2},
numpages = {6},
keywords = {Web accessibility, Evaluation Tools, Automated Metrics},
location = {Larache, Morocco},
series = {NISS '23}
}

@inproceedings{comparative_accessibility_methods,
author={Brajnik, Giorgio},
title = {A comparative test of web accessibility evaluation methods},
year = {2008},
isbn = {9781595939760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1414471.1414494},
doi = {10.1145/1414471.1414494},
abstract = {Accessibility auditors have to choose a method when evaluating accessibility: expert review (a.k.a. conformance testing), user testing, subjective evaluations, barrier walkthrough are some possibilities. However, little is known to date about their relative strengths and weaknesses. Furthermore, what happened for usability evaluation methods is likely to repeat for accessibility: that there is uncertainty about not only pros and cons of methods, but also about criteria to be used to compare them and metrics to measure these criteria. After a quick review and description of methods, the paper illustrates a comparative test of two web accessibility evaluation methods: conformance testing and barrier walkthrough. The comparison aims at determining merits of barrier walkthrough, using conformance testing as a control condition. A comparison framework is outlined, followed by the description of a laboratory experiment with 12 subjects (novice accessibility evaluators), and its results. Significant differences were found in terms of correctness, one of the several metrics used to compare the methods. Reliability also appears to be different.},
booktitle = {Proceedings of the 10th International ACM SIGACCESS Conference on Computers and Accessibility},
pages = {113–120},
numpages = {8},
keywords = {web accessibility, quality assessment, accessibility evaluation method},
location = {Halifax, Nova Scotia, Canada},
series = {Assets '08}
}

@Article{Brajnik2004,
author={Brajnik, Giorgio},
title={Comparing accessibility evaluation tools: a method for tool effectiveness},
journal={Universal Access in the Information Society},
year={2004},
month={Oct},
day={01},
volume={3},
number={3},
pages={252-263},
abstract={This paper claims that effectiveness of automatic tools for evaluating web site accessibility has to be itself evaluated, given the increasingly important role that these tools play. The paper presents a comparison method for a pair of tools that takes into account correctness, completeness and specificity in supporting the task of assessing the conformance of a web site with respect to established guidelines. The paper presents data acquired during a case study based on comparing LIFT Machine with Bobby. The data acquired from the case study is used to assess the strengths and weaknesses of the comparison method. The conclusion is that even though there is room for improvement of the method, it is already capable of providing accurate and reliable conclusions.},
issn={1615-5297},
doi={10.1007/s10209-004-0105-y},
url={https://doi.org/10.1007/s10209-004-0105-y}
}

@inproceedings{10.1145/1878803.1878813_testability_expertise,
author = {Brajnik, Giorgio and Yesilada, Yeliz and Harper, Simon},
title = {Testability and validity of WCAG 2.0: the expertise effect},
year = {2010},
isbn = {9781605588810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1878803.1878813},
doi = {10.1145/1878803.1878813},
abstract = {Web Content Accessibility Guidelines 2.0 (WCAG 2.0) require that success criteria be tested by human inspection. Further, testability of WCAG 2.0 criteria is achieved if 80\% of knowledgeable inspectors agree that the criteria has been met or not. In this paper we investigate the very core WCAG 2.0, being their ability to determine web content accessibility conformance. We conducted an empirical study to ascertain the testability of WCAG 2.0 success criteria when experts and non-experts evaluated four relatively complex web pages; and the differences between the two. Further, we discuss the validity of the evaluations generated by these inspectors and look at the differences in validity due to expertise.In summary, our study, comprising 22 experts and 27 non-experts, shows that approximately 50\% of success criteria fail to meet the 80\% agreement threshold; experts produce 20\% false positives and miss 32\% of the true problems. We also compared the performance of experts against that of non-experts and found that agreement for the non-experts dropped by 6\%, false positives reach 42\% and false negatives 49\%. This suggests that in many cases WCAG 2.0 conformance cannot be tested by human inspection to a level where it is believed that at least 80\% of knowledgeable human evaluators would agree on the conclusion. Why experts fail to meet the 80\% threshold and what can be done to help achieve this level are the subjects of further investigation.},
booktitle = {Proceedings of the 12th International ACM SIGACCESS Conference on Computers and Accessibility},
pages = {43–50},
numpages = {8},
keywords = {evaluation, expertise, guideline, web accessibility},
location = {Orlando, Florida, USA},
series = {ASSETS '10}
}


@article{designsciencemethodology,
 ISSN = {02767783},
 URL = {http://www.jstor.org/stable/25148625},
 abstract = {Two paradigms characterize much of the research in the Information Systems discipline: behavioral science and design science. The behavioral-science paradigm seeks to develop and verify theories that explain or predict human or organizational behavior. The design-science paradigm seeks to extend the boundaries of human and organizational capabilities by creating new and innovative artifacts. Both paradigms are foundational to the IS discipline, positioned as it is at the confluence of people, organizations, and technology. Our objective is to describe the performance of design-science research in Information Systems via a concise conceptual framework and clear guidelines for understanding, executing, and evaluating the research. In the design-science paradigm, knowledge and understanding of a problem domain and its solution are achieved in the building and application of the designed artifact. Three recent exemplars in the research literature are used to demonstrate the application of these guidelines. We conclude with an analysis of the challenges of performing high-quality design-science research in the context of the broader IS community.},
 author = {Alan R. Hevner and Salvatore T. March and Jinsoo Park and Sudha Ram},
 journal = {MIS Quarterly},
 number = {1},
 pages = {75--105},
 publisher = {Management Information Systems Research Center, University of Minnesota},
 title = {Design Science in Information Systems Research},
 urldate = {2024-03-15},
 volume = {28},
 year = {2004}
}

@article{iterativedesignscience,
author = {Peffers, Ken and Tuunanen, Tuure and Rothenberger, Marcus and Chatterjee, Samir},
title = {A Design Science Research Methodology for Information Systems Research},
year = {2007},
issue_date = {Number 3 / Winter 2007-2008},
publisher = {M. E. Sharpe, Inc.},
address = {USA},
volume = {24},
number = {3},
issn = {0742-1222},
url = {https://doi.org/10.2753/MIS0742-1222240302},
doi = {10.2753/MIS0742-1222240302},
abstract = {The paper motivates, presents, demonstrates in use, and evaluates a methodology for conducting design science (DS) research in information systems (IS). DS is of importance in a discipline oriented to the creation of successful artifacts. Several researchers have pioneered DS research in IS, yet over the past 15 years, little DS research has been done within the discipline. The lack of a methodology to serve as a commonly accepted framework for DS research and of a template for its presentation may have contributed to its slow adoption. The design science research methodology (DSRM) presented here incorporates principles, practices, and procedures required to carry out such research and meets three objectives: it is consistent with prior literature, it provides a nominal process model for doing DS research, and it provides a mental model for presenting and evaluating DS research in IS. The DS process includes six steps: problem identification and motivation, definition of the objectives for a solution, design and development, demonstration, evaluation, and communication. We demonstrate and evaluate the methodology by presenting four case studies in terms of the DSRM, including cases that present the design of a database to support health assessment methods, a software reuse measure, an Internet video telephony application, and an IS planning method. The designed methodology effectively satisfies the three objectives and has the potential to help aid the acceptance of DS research in the IS discipline.},
journal = {J. Manage. Inf. Syst.},
month = {dec},
pages = {45–77},
numpages = {33},
keywords = {Case Study, Design Science, Design Science Research, Design Theory, Mental Model, Methodology, Process Model}
}

@article{design_science_eval,
author = {Ken Peffers and Tuure Tuunanen and Björn Niehaves},
title = {Design science research genres: introduction to the special issue on exemplars and criteria for applicable design science research},
journal = {European Journal of Information Systems},
volume = {27},
number = {2},
pages = {129--139},
year = {2018},
publisher = {Taylor \& Francis},
doi = {10.1080/0960085X.2018.1458066},
URL = {https://doi.org/10.1080/0960085X.2018.1458066},
}

@inproceedings{tooltransparency,
author = {Parvin, Parvaneh and Palumbo, Vanessa and Manca, Marco and Patern\`{o}, Fabio},
title = {The transparency of automatic accessibility evaluation tools},
year = {2021},
isbn = {9781450382120},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3430263.3452436},
doi = {10.1145/3430263.3452436},
abstract = {Several web accessibility evaluation tools have been put forward to reduce the burden of identifying accessibility barriers for disabled people. One common issue in using accessibility evaluation tools in practice is that the results provided by different tools are often variable. Such variability may confuse the users who may not understand the reasons behind it, and thus limits the possible adoption of such tools. Hence, there is a need to shed light on the tools' actual functioning, indicate what criteria they should adopt to be transparent and to help users better interpret their results. In this communication paper, we discuss such issues, analyse how they have been addressed by a representative set of tools, and provide useful indications for obtaining user-centred accessibility evaluations.},
booktitle = {Proceedings of the 18th International Web for All Conference},
articleno = {10},
numpages = {5},
keywords = {transparency, automatic validation tools, accessibility},
location = {Ljubljana, Slovenia},
series = {W4A '21}
}

@inproceedings{chen2020unblind,
author = {Chen, Jieshan and Chen, Chunyang and Xing, Zhenchang and Xu, Xiwei and Zhu, Liming and Li, Guoqiang and Wang, Jinshui},
title = {Unblind Your Apps: Predicting Natural-Language Labels for Mobile GUI Components by Deep Learning},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380327},
doi = {10.1145/3377811.3380327},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {322–334},
numpages = {13},
keywords = {accessibility, neural networks, content description, user interface, image-based buttons},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{perceived_usefulness,
author = {Fred Davis},
year = {1989},
month = {09},
pages = {319-},
title = {Perceived Usefulness, Perceived Ease of Use, and User Acceptance of Information Technology},
volume = {13},
journal = {MIS Quarterly},
doi = {10.2307/249008}
}